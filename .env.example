# LLM Provider Configuration
# Choose your preferred LLM provider: "ollama" or "openai"
LLM_PROVIDER=ollama

# Ollama Configuration
# Model to use for question generation (default: llama3.2)
OLLAMA_MODEL=llama3.2
# Ollama host URL (default: http://localhost:11434)
OLLAMA_HOST=http://localhost:11434

# OpenAI Configuration
# Your OpenAI API key (required for OpenAI provider)
OPENAI_API_KEY=your-openai-api-key-here
# OpenAI model to use (default: gpt-4o-mini)
OPENAI_MODEL=gpt-4o-mini

# Question Generation Settings
# Default number of questions to generate
DEFAULT_QUESTION_LIMIT=5
# Custom prompt template (optional)
CUSTOM_PROMPT_TEMPLATE=

# Application Settings
# FastAPI host and port
APP_HOST=0.0.0.0
APP_PORT=8000
# Database file path
DATABASE_PATH=quiz.db

# Logging Configuration
# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO